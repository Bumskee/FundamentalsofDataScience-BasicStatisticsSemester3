{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1e0soRg-cCz2"
      },
      "outputs": [],
      "source": [
        "# import all of the necessary modules and libraries\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from csv import writer\n",
        "import re\n",
        "import pandas as pd\n",
        "from pandas.core.frame import DataFrame\n",
        "from datetime import datetime\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "spIUFL75L6kk"
      },
      "outputs": [],
      "source": [
        "def is_time_between(begin_time, end_time, check_time):\n",
        "    return begin_time <= check_time <= end_time\n",
        "\n",
        "def avg(arr):\n",
        "  try:\n",
        "    return sum(arr)/len(arr)\n",
        "  except: \n",
        "    return np.nan\n",
        "\n",
        "def removeBlank(dataBase):\n",
        "  temp = dataBase.drop(dataBase[dataBase.overall == ''].index)\n",
        "  return temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "6SqCFKfcUBHZ"
      },
      "outputs": [],
      "source": [
        "genre = \"horror\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# WARNING ONLY RUN THIS ONCE !!!!\n",
        "# WARNING ONLY RUN THIS ONCE !!!!\n",
        "# WARNING ONLY RUN THIS ONCE !!!!\n",
        "# WARNING ONLY RUN THIS ONCE !!!!\n",
        "# WARNING ONLY RUN THIS ONCE !!!!\n",
        "# WARNING ONLY RUN THIS ONCE !!!!\n",
        "# WARNING ONLY RUN THIS ONCE !!!!\n",
        "# WARNING ONLY RUN THIS ONCE !!!!\n",
        "# WARNING ONLY RUN THIS ONCE !!!!\n",
        "# WARNING ONLY RUN THIS ONCE !!!!\n",
        "# WARNING ONLY RUN THIS ONCE !!!!\n",
        "# WARNING ONLY RUN THIS ONCE !!!!\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"film_id\": [],\n",
        "    \"rating\": [],\n",
        "    \"date\": []\n",
        "})\n",
        "\n",
        "df.to_csv('result/' + genre + '/' + genre + '.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgeUir_MIOcz",
        "outputId": "8b222f88-1a2c-4ce3-dfe8-e361ef1b153a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "this is movie 20001\n"
          ]
        }
      ],
      "source": [
        "#scraping code (newVersion)\n",
        "\n",
        "fileName = genre + \".csv\"\n",
        "movies = pd.read_csv(fileName)\n",
        "headers = {'Accept-Language': 'en-US,en;q=0.8'}\n",
        "\n",
        "for i in range(20000, 20001):\n",
        "    movie = movies[genre][i]\n",
        "    print(f\"this is movie {i+1}\")\n",
        "    url = 'https://www.imdb.com' + movie + \"reviews\"\n",
        "    response = requests.get(url,headers=headers)\n",
        "    soup = BeautifulSoup(response.text, \"html\")\n",
        "\n",
        "    datas = []\n",
        "    ratings = []\n",
        "    dates = []\n",
        "\n",
        "    # takes the initial ratings and dates that is available in the first page (if its available)\n",
        "    try:\n",
        "        ratings = [int(rating.find('span').text) for rating in soup.find_all(\"span\", {\"class\":\"rating-other-user-rating\"})]\n",
        "        dates = [str(datetime.strptime(date.text, '%d %B %Y').date()) for date in soup.find_all('span', {'class':'review-date'})]\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    more = soup.find(\"div\", {\"class\":\"load-more-data\"})\n",
        "    try:\n",
        "      ajaxurl = more['data-ajaxurl']\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "    there_is_more = False\n",
        "\n",
        "    # check first if there is any load more button in the review page\n",
        "    try:\n",
        "        more[\"data-key\"]\n",
        "        there_is_more = True\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    while (there_is_more):\n",
        "        url = 'https://www.imdb.com' + ajaxurl + '?paginationKey=' + more[\"data-key\"]\n",
        "        response = requests.get(url,headers=headers)\n",
        "        soup = BeautifulSoup(response.text, \"html\") \n",
        "\n",
        "        # check the additional ratings and dates then append it to the base ratings and dates\n",
        "        ratings_ = [int(rating.find('span').text) for rating in soup.find_all(\"span\", {\"class\":\"rating-other-user-rating\"})]\n",
        "        dates_ = [str(datetime.strptime(date.text, '%d %B %Y').date()) for date in soup.find_all('span', {'class':'review-date'})]\n",
        "\n",
        "        for j in range(len(ratings_)):\n",
        "            ratings.append(ratings_[j])\n",
        "            dates.append(dates_[j])\n",
        "\n",
        "        # find the load-more-data button information\n",
        "        more = soup.find(\"div\", {\"class\":\"load-more-data\"})\n",
        "\n",
        "        # check if there are more reviews\n",
        "        try:\n",
        "            more[\"data-key\"]\n",
        "        except:\n",
        "            there_is_more = False\n",
        "    \n",
        "    for z in range(len(ratings)):\n",
        "        datas.append([i, ratings[z], dates[z]])\n",
        "\n",
        "    df = pd.DataFrame(data = datas)\n",
        "    df.to_csv('result/' + genre + '/' + genre + '.csv', mode = 'a' ,index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#scraping code (oldVersion)\n",
        "\n",
        "fileName = genre + \".csv\"\n",
        "movies = pd.read_csv(fileName)\n",
        "headers = {'Accept-Language': 'en-US,en;q=0.8'}\n",
        "\n",
        "for i in range(0, 3000):\n",
        "    print(f\"this is movie {i+1} out of 3000\")\n",
        "    url = 'https://www.imdb.com' + movies[genre][i] + \"reviews\"\n",
        "    response = requests.get(url,headers=headers)\n",
        "    soup = BeautifulSoup(response.text, \"html\")\n",
        "\n",
        "    ratings = []\n",
        "    dates = []\n",
        "\n",
        "    # takes the initial ratings and dates that is available in the first page (if its available)\n",
        "    try:\n",
        "        ratings = [int(rating.find('span').text) for rating in soup.find_all(\"span\", {\"class\":\"rating-other-user-rating\"})]\n",
        "        dates = [str(datetime.strptime(date.text, '%d %B %Y').date()) for date in soup.find_all('span', {'class':'review-date'})]\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    more = soup.find(\"div\", {\"class\":\"load-more-data\"})\n",
        "    try:\n",
        "      ajaxurl = more['data-ajaxurl']\n",
        "    except:\n",
        "      continue\n",
        "\n",
        "    there_is_more = False\n",
        "\n",
        "    # check first if there is any load more button in the review page\n",
        "    try:\n",
        "        more[\"data-key\"]\n",
        "        there_is_more = True\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    while (there_is_more):\n",
        "        url = 'https://www.imdb.com' + ajaxurl + '?paginationKey=' + more[\"data-key\"]\n",
        "        response = requests.get(url,headers=headers)\n",
        "        soup = BeautifulSoup(response.text, \"html\") \n",
        "\n",
        "        # check the additional ratings and dates then append it to the base ratings and dates\n",
        "        ratings_ = [int(rating.find('span').text) for rating in soup.find_all(\"span\", {\"class\":\"rating-other-user-rating\"})]\n",
        "        dates_ = [str(datetime.strptime(date.text, '%d %B %Y').date()) for date in soup.find_all('span', {'class':'review-date'})]\n",
        "\n",
        "        for j in range(len(ratings_)):\n",
        "            ratings.append(ratings_[j])\n",
        "            dates.append(dates_[j])\n",
        "\n",
        "        # find the load-more-data button information\n",
        "        more = soup.find(\"div\", {\"class\":\"load-more-data\"})\n",
        "\n",
        "        # check if there are more reviews\n",
        "        try:\n",
        "            more[\"data-key\"]\n",
        "        except:\n",
        "            there_is_more = False\n",
        "    \n",
        "    # empty list for the datas to be appended in\n",
        "    christmas2015 = []\n",
        "    winter2015 = []\n",
        "    valentine2015 = []\n",
        "    spring2015 = []\n",
        "    summer2015 = []\n",
        "    fall2015 = []\n",
        "    halloween2015 = []\n",
        "\n",
        "    christmas2016 = []\n",
        "    winter2016 = []\n",
        "    valentine2016 = []\n",
        "    spring2016 = []\n",
        "    summer2016 = []\n",
        "    fall2016 = []\n",
        "    halloween2016 = []\n",
        "\n",
        "    christmas2017 = []\n",
        "    winter2017 = []\n",
        "    valentine2017 = []\n",
        "    spring2017 = []\n",
        "    summer2017 = []\n",
        "    fall2017 = []\n",
        "    halloween2017 = []\n",
        "\n",
        "    christmas2018 = []\n",
        "    winter2018 = []\n",
        "    valentine2018 = []\n",
        "    spring2018 = []\n",
        "    summer2018 = []\n",
        "    fall2018 = []\n",
        "    halloween2018 = []\n",
        "\n",
        "    christmas2019 = []\n",
        "    winter2019 = []\n",
        "    valentine2019 = []\n",
        "    spring2019 = []\n",
        "    summer2019 = []\n",
        "    fall2019 = []\n",
        "    halloween2019 = []\n",
        "\n",
        "    christmas2020 = []\n",
        "    winter2020 = []\n",
        "    valentine2020 = []\n",
        "    spring2020 = []\n",
        "    summer2020 = []\n",
        "    fall2020 = []\n",
        "    halloween2020 = []\n",
        "\n",
        "    for z in range(len(ratings)):\n",
        "        # check the year if it is within the year range\n",
        "        if not (is_time_between(datetime.strptime(\"2015\", '%Y').date(), datetime.strptime(\"2020\", '%Y').date(), datetime.strptime(dates[z][0:4], '%Y').date())):\n",
        "          continue\n",
        "        \n",
        "        # sometimes the date is null and would return an error\n",
        "        try:\n",
        "          compared = datetime.strptime(dates[z][5:10], '%m-%d').date()\n",
        "        except:\n",
        "          continue\n",
        "\n",
        "        if (is_time_between(datetime.strptime(\"12-10\", '%m-%d').date(), datetime.strptime(\"12-31\", '%m-%d').date(), compared) or is_time_between(datetime.strptime(\"01-01\", '%m-%d').date(), datetime.strptime(\"01-10\", '%m-%d').date(), compared)):\n",
        "          exec(f'christmas{dates[z][0:4]}.append(ratings[z])')\n",
        "\n",
        "        if (is_time_between(datetime.strptime(\"12-01\", '%m-%d').date(), datetime.strptime(\"12-31\", '%m-%d').date(), compared) or is_time_between(datetime.strptime(\"01-01\", '%m-%d').date(), datetime.strptime(\"02-28\", '%m-%d').date(), compared)):\n",
        "          exec(f'winter{dates[z][0:4]}.append(ratings[z])')\n",
        "\n",
        "        if (is_time_between(datetime.strptime(\"02-01\", '%m-%d').date(), datetime.strptime(\"02-28\", '%m-%d').date(), compared)):\n",
        "          exec(f'valentine{dates[z][0:4]}.append(ratings[z])')\n",
        "\n",
        "        if (is_time_between(datetime.strptime(\"03-01\", '%m-%d').date(), datetime.strptime(\"05-31\", '%m-%d').date(), compared)):\n",
        "          exec(f'spring{dates[z][0:4]}.append(ratings[z])')\n",
        "\n",
        "        if (is_time_between(datetime.strptime(\"06-01\", '%m-%d').date(), datetime.strptime(\"08-31\", '%m-%d').date(), compared)):\n",
        "          exec(f'summer{dates[z][0:4]}.append(ratings[z])')\n",
        "\n",
        "        if (is_time_between(datetime.strptime(\"09-01\", '%m-%d').date(), datetime.strptime(\"11-30\", '%m-%d').date(), compared)):\n",
        "          exec(f'fall{dates[z][0:4]}.append(ratings[z])')\n",
        "\n",
        "        if (is_time_between(datetime.strptime(\"10-21\", '%m-%d').date(), datetime.strptime(\"12-09\", '%m-%d').date(), compared)):\n",
        "          exec(f'halloween{dates[z][0:4]}.append(ratings[z])')\n",
        "\n",
        "    # used to calculate the average rating per year\n",
        "    average2015 = christmas2015 + winter2017 + valentine2015 + spring2015 + summer2015 + fall2015 + halloween2015\n",
        "    average2016 = christmas2016 + winter2016 + valentine2016 + spring2016 + summer2016 + fall2016 + halloween2016\n",
        "    average2017 = christmas2017 + winter2017 + valentine2017 + spring2017 + summer2017 + fall2017 + halloween2017\n",
        "    average2018 = christmas2018 + winter2018 + valentine2018 + spring2018 + summer2018 + fall2018 + halloween2018\n",
        "    average2019 = christmas2019 + winter2019 + valentine2019 + spring2019 + summer2019 + fall2019 + halloween2019\n",
        "    average2020 = christmas2020 + winter2020 + valentine2020 + spring2020 + summer2020 + fall2020 + halloween2020\n",
        "\n",
        "    # new rows to be appended into the dataset\n",
        "    data2015 = [avg(christmas2015), avg(winter2015), avg(valentine2015), avg(spring2015), avg(summer2015), avg(fall2015), avg(halloween2015), avg(average2015), avg(ratings)]\n",
        "    data2016 = [avg(christmas2016), avg(winter2016), avg(valentine2016), avg(spring2016), avg(summer2016), avg(fall2016), avg(halloween2016), avg(average2016), avg(ratings)]\n",
        "    data2017 = [avg(christmas2017), avg(winter2017), avg(valentine2017), avg(spring2017), avg(summer2017), avg(fall2017), avg(halloween2017), avg(average2017), avg(ratings)]\n",
        "    data2018 = [avg(christmas2018), avg(winter2018), avg(valentine2018), avg(spring2018), avg(summer2018), avg(fall2018), avg(halloween2018), avg(average2018), avg(ratings)]\n",
        "    data2019 = [avg(christmas2019), avg(winter2019), avg(valentine2019), avg(spring2019), avg(summer2019), avg(fall2019), avg(halloween2019), avg(average2019), avg(ratings)]\n",
        "    data2020 = [avg(christmas2020), avg(winter2020), avg(valentine2020), avg(spring2020), avg(summer2020), avg(fall2020), avg(halloween2020), avg(average2020), avg(ratings)]\n",
        "\n",
        "    with open('result/' + genre + '/2015.csv', 'a') as f_object:\n",
        "      writer_object = writer(f_object)\n",
        "      writer_object.writerow(data2015)\n",
        "      f_object.close()\n",
        "\n",
        "    with open('result/' + genre + '/2016.csv', 'a') as f_object:\n",
        "      writer_object = writer(f_object)\n",
        "      writer_object.writerow(data2016)\n",
        "      f_object.close()\n",
        "\n",
        "    with open('result/' + genre + '/2017.csv', 'a') as f_object:\n",
        "      writer_object = writer(f_object)\n",
        "      writer_object.writerow(data2017)\n",
        "      f_object.close()\n",
        "\n",
        "    with open('result/' + genre + '/2018.csv', 'a') as f_object:\n",
        "      writer_object = writer(f_object)\n",
        "      writer_object.writerow(data2018)\n",
        "      f_object.close()\n",
        "\n",
        "    with open('result/' + genre + '/2019.csv', 'a') as f_object:\n",
        "      writer_object = writer(f_object)\n",
        "      writer_object.writerow(data2019)\n",
        "      f_object.close()\n",
        "\n",
        "    with open('result/' + genre + '/2020.csv', 'a') as f_object:\n",
        "      writer_object = writer(f_object)\n",
        "      writer_object.writerow(data2020)\n",
        "      f_object.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(2015, 2021):\n",
        "    removeBlank(pd.read_csv('result/' + genre + '/' + str(i) + '.csv')).to_csv('fixed/' + genre + '/' + str(i) + '.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "RatingScrapingAFKMethod.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
